# credit_scoring.py

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve
import xgboost as xgb
import warnings
import os
import sys
from datetime import datetime

warnings.filterwarnings('ignore')

# üîß –ü–†–û–í–ï–†–ö–ê PLOTLY
try:
    import plotly
    PLOTLY_AVAILABLE = True
    print("‚úÖ Plotly –¥–æ—Å—Ç—É–ø–µ–Ω")
except ImportError:
    PLOTLY_AVAILABLE = False
    print("‚ö†Ô∏è Plotly –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
    
class CreditScoringModel:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ –∫—Ä–µ–¥–∏—Ç–Ω–æ–≥–æ —Å–∫–æ—Ä–∏–Ω–≥–∞
    """
    
    def __init__(self):
        self.df = None
        self.models = {}
        self.results = {}
        self.best_model = None
        self.scaler = StandardScaler()
        self.label_encoders = {}
        
    def load_data(self, source='online'):
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        """
        print("üìä –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–•...")
        print("-" * 50)
        
        if source == 'online':
            # –ó–∞–≥—Ä—É–∑–∫–∞ —Å UCI
            try:
                url = "https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data"
                column_names = [
                    'checking_account', 'duration', 'credit_history', 'purpose', 'credit_amount',
                    'savings_account', 'employment', 'installment_rate', 'personal_status_sex',
                    'other_debtors', 'present_residence', 'property', 'age', 'other_installment_plans',
                    'housing', 'number_credits', 'job', 'people_liable', 'telephone', 'foreign_worker', 'credit_risk'
                ]
                self.df = pd.read_csv(url, delim_whitespace=True, names=column_names, header=None)
                print("‚úÖ German Credit Dataset —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω —Å UCI!")
                
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å UCI: {e}")
                self._create_sample_data()
                
        elif source == 'local':
            # –ó–∞–≥—Ä—É–∑–∫–∞ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
            try:
                self.df = pd.read_csv('data/german_credit.csv')
                print("‚úÖ –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞!")
            except:
                print("‚ùå –õ–æ–∫–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω. –°–æ–∑–¥–∞–µ–º –¥–µ–º–æ-–¥–∞–Ω–Ω—ã–µ...")
                self._create_sample_data()
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
        if 'credit_risk' in self.df.columns:
            self.df['target'] = self.df['credit_risk'].map({1: 0, 2: 1})
            print("‚úÖ –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∞")
        
        print(f"üìä –†–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞: {self.df.shape}")
        print(f"üéØ –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤:")
        print(self.df['target'].value_counts())
        
        return self.df
    
    def _create_sample_data(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –¥–µ–º–æ-–¥–∞–Ω–Ω—ã—Ö –µ—Å–ª–∏ –∑–∞–≥—Ä—É–∑–∫–∞ –Ω–µ —É–¥–∞–ª–∞—Å—å"""
        print("üîÑ –°–æ–∑–¥–∞–Ω–∏–µ –¥–µ–º–æ-–¥–∞—Ç–∞—Å–µ—Ç–∞...")
        np.random.seed(42)
        n_samples = 1000
        
        self.df = pd.DataFrame({
            'checking_account': np.random.choice(['A11', 'A12', 'A13', 'A14'], n_samples),
            'duration': np.random.randint(6, 72, n_samples),
            'credit_history': np.random.choice(['A30', 'A31', 'A32', 'A33', 'A34'], n_samples),
            'credit_amount': np.random.randint(250, 18424, n_samples),
            'savings_account': np.random.choice(['A61', 'A62', 'A63', 'A64', 'A65'], n_samples),
            'employment': np.random.choice(['A71', 'A72', 'A73', 'A74', 'A75'], n_samples),
            'age': np.random.randint(19, 75, n_samples),
            'target': np.random.choice([0, 1], n_samples, p=[0.7, 0.3])
        })
        print("‚úÖ –î–µ–º–æ-–¥–∞—Ç–∞—Å–µ—Ç —Å–æ–∑–¥–∞–Ω")
    
    def explore_data(self):
        """
        –ê–Ω–∞–ª–∏–∑ –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
        """
        print("\nüìä –ê–ù–ê–õ–ò–ó –î–ê–ù–ù–´–•...")
        print("-" * 50)
        
        # –ë–∞–∑–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        print("üìã –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞–Ω–Ω—ã—Ö:")
        print(self.df.info())
        
        print("\nüìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:")
        print(self.df.describe())
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π
        self._create_visualizations()
        
    def _create_visualizations(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤ –¥–ª—è EDA"""
        print("üìä –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π...")
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle('–ê–ù–ê–õ–ò–ó –ö–†–ï–î–ò–¢–ù–´–• –î–ê–ù–ù–´–•', fontsize=16, fontweight='bold')
        
        # 1. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
        target_counts = self.df['target'].value_counts()
        axes[0,0].pie(target_counts.values,
                    labels=[f'–•–æ—Ä–æ—à–∏–µ ({target_counts[0]})', f'–ü–ª–æ—Ö–∏–µ ({target_counts[1]})'],
                    autopct='%1.1f%%', colors=['lightgreen', 'lightcoral'], startangle=90)
        axes[0,0].set_title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ –∫–ª–∏–µ–Ω—Ç–æ–≤', fontweight='bold')
        
        # 2. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—É–º–º—ã –∫—Ä–µ–¥–∏—Ç–∞
        if 'credit_amount' in self.df.columns:
            axes[0,1].hist(self.df['credit_amount'], bins=30, alpha=0.7, color='skyblue', edgecolor='black')
            axes[0,1].set_xlabel('–°—É–º–º–∞ –∫—Ä–µ–¥–∏—Ç–∞ (DM)')
            axes[0,1].set_ylabel('–ß–∞—Å—Ç–æ—Ç–∞')
            axes[0,1].set_title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—É–º–º—ã –∫—Ä–µ–¥–∏—Ç–∞', fontweight='bold')
            axes[0,1].grid(True, alpha=0.3)
        
        # 3. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–æ–∑—Ä–∞—Å—Ç–∞
        if 'age' in self.df.columns:
            axes[1,0].hist(self.df['age'], bins=20, alpha=0.7, color='lightcoral', edgecolor='black')
            axes[1,0].set_xlabel('–í–æ–∑—Ä–∞—Å—Ç')
            axes[1,0].set_ylabel('–ß–∞—Å—Ç–æ—Ç–∞')
            axes[1,0].set_title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–æ–∑—Ä–∞—Å—Ç–∞', fontweight='bold')
            axes[1,0].grid(True, alpha=0.3)
        
        # 4. –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞
        numeric_columns = self.df.select_dtypes(include=[np.number]).columns
        if len(numeric_columns) > 1:
            correlation_matrix = self.df[numeric_columns].corr()
            sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, ax=axes[1,1],
                    fmt='.2f', annot_kws={'size': 8})
            axes[1,1].set_title('–ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞', fontweight='bold')
        
        plt.tight_layout()
        plt.savefig('eda_visualization.png', dpi=300, bbox_inches='tight')
        print("‚úÖ –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ 'eda_visualization.png'")
        plt.show()
    
    def preprocess_data(self):
        """
        –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏ feature engineering
        """
        print("\nüîß –ü–†–ï–î–û–ë–†–ê–ë–û–¢–ö–ê –î–ê–ù–ù–´–•...")
        print("-" * 50)
        
        df_processed = self.df.copy()
        
        # –£–¥–∞–ª—è–µ–º —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é
        y = df_processed['target']
        df_processed = df_processed.drop('target', axis=1)
        
        # –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
        categorical_columns = df_processed.select_dtypes(include=['object']).columns
        
        for col in categorical_columns:
            le = LabelEncoder()
            df_processed[col] = le.fit_transform(df_processed[col].astype(str))
            self.label_encoders[col] = le
            print(f"‚úÖ –ó–∞–∫–æ–¥–∏—Ä–æ–≤–∞–Ω: {col}")
        
        # Feature engineering
        if 'credit_amount' in df_processed.columns and 'age' in df_processed.columns:
            df_processed['amount_to_age_ratio'] = df_processed['credit_amount'] / (df_processed['age'] + 1)
            print("‚úÖ –°–æ–∑–¥–∞–Ω –ø—Ä–∏–∑–Ω–∞–∫: amount_to_age_ratio")
        
        if 'duration' in df_processed.columns and 'credit_amount' in df_processed.columns:
            df_processed['duration_to_amount_ratio'] = df_processed['duration'] / (df_processed['credit_amount'] + 1)
            print("‚úÖ –°–æ–∑–¥–∞–Ω –ø—Ä–∏–∑–Ω–∞–∫: duration_to_amount_ratio")
        
        self.X = df_processed
        self.y = y
        
        print(f"‚úÖ –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –ü—Ä–∏–∑–Ω–∞–∫–æ–≤: {self.X.shape[1]}")
        
        return self.X, self.y
    
    def train_models(self):
        """
        –û–±—É—á–µ–Ω–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö ML –º–æ–¥–µ–ª–µ–π
        """
        print("\nü§ñ –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ï–ô...")
        print("-" * 50)
        
        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
        X_train, X_test, y_train, y_test = train_test_split(
            self.X, self.y, test_size=0.2, random_state=42, stratify=self.y
        )
        
        # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)
        
        print(f"üìä –û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞: {X_train.shape[0]} –∫–ª–∏–µ–Ω—Ç–æ–≤")
        print(f"üìä –¢–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞: {X_test.shape[0]} –∫–ª–∏–µ–Ω—Ç–æ–≤")
        
        # –ú–æ–¥–µ–ª–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        self.models = {
            'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),
            'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),
            'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),
            'XGBoost': xgb.XGBClassifier(n_estimators=100, random_state=42, eval_metric='logloss')
        }
        
        # –û–±—É—á–µ–Ω–∏–µ –∏ –æ—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–µ–π
        for name, model in self.models.items():
            print(f"üîÑ –û–±—É—á–µ–Ω–∏–µ {name}...")
            
            try:
                # –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è
                cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='accuracy')
                
                # –û–±—É—á–µ–Ω–∏–µ
                model.fit(X_train_scaled, y_train)
                
                # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
                y_pred = model.predict(X_test_scaled)
                y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]
                
                # –ú–µ—Ç—Ä–∏–∫–∏
                accuracy = accuracy_score(y_test, y_pred)
                roc_auc = roc_auc_score(y_test, y_pred_proba)
                
                self.results[name] = {
                    'model': model,
                    'cv_mean': cv_scores.mean(),
                    'cv_std': cv_scores.std(),
                    'test_accuracy': accuracy,
                    'roc_auc': roc_auc,
                    'predictions': y_pred,
                    'probabilities': y_pred_proba
                }
                
                print(f"   ‚úÖ CV Accuracy: {cv_scores.mean():.3f} ¬± {cv_scores.std():.3f}")
                print(f"   ‚úÖ Test Accuracy: {accuracy:.3f}")
                print(f"   ‚úÖ ROC-AUC: {roc_auc:.3f}")
                
            except Exception as e:
                print(f"   ‚ùå –û—à–∏–±–∫–∞: {e}")
        
        # –í—ã–±–æ—Ä –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
        if self.results:
            self.best_model_name = max(self.results.keys(), key=lambda x: self.results[x]['roc_auc'])
            self.best_model = self.results[self.best_model_name]['model']
            self.best_accuracy = self.results[self.best_model_name]['test_accuracy']
            self.best_auc = self.results[self.best_model_name]['roc_auc']
            
            print(f"\nüéØ –õ–£–ß–®–ê–Ø –ú–û–î–ï–õ–¨: {self.best_model_name}")
            print(f"üèÜ –¢–û–ß–ù–û–°–¢–¨: {self.best_accuracy:.3f}")
            print(f"üéØ ROC-AUC: {self.best_auc:.3f}")
        
        self.X_test = X_test
        self.y_test = y_test
        self.X_test_scaled = X_test_scaled
        
        return self.results
    
    def evaluate_models(self):
        """
        –î–µ—Ç–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        """
        if not self.results:
            print("‚ùå –ú–æ–¥–µ–ª–∏ –Ω–µ –æ–±—É—á–µ–Ω—ã!")
            return
        
        print("\nüìà –û–¶–ï–ù–ö–ê –†–ï–ó–£–õ–¨–¢–ê–¢–û–í...")
        print("-" * 50)
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle('–†–ï–ó–£–õ–¨–¢–ê–¢–´ –ú–û–î–ï–õ–ò –ö–†–ï–î–ò–¢–ù–û–ì–û –°–ö–û–†–ò–ù–ì–ê', fontsize=16, fontweight='bold')
        
        # 1. –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
        y_pred_best = self.results[self.best_model_name]['predictions']
        cm = confusion_matrix(self.y_test, y_pred_best)
        
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0,0],
                xticklabels=['–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω –•–æ—Ä–æ—à–∏–π', '–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω –ü–ª–æ—Ö–æ–π'],
                yticklabels=['–§–∞–∫—Ç–∏—á–µ—Å–∫–∏–π –•–æ—Ä–æ—à–∏–π', '–§–∞–∫—Ç–∏—á–µ—Å–∫–∏–π –ü–ª–æ—Ö–æ–π'])
        axes[0,0].set_title('–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫', fontweight='bold')
        
        # 2. ROC-–∫—Ä–∏–≤—ã–µ
        for name, result in self.results.items():
            fpr, tpr, _ = roc_curve(self.y_test, result['probabilities'])
            axes[0,1].plot(fpr, tpr, label=f'{name} (AUC = {result["roc_auc"]:.3f})', linewidth=2)
        
        axes[0,1].plot([0, 1], [0, 1], 'k--', alpha=0.5, label='–°–ª—É—á–∞–π–Ω–∞—è –º–æ–¥–µ–ª—å')
        axes[0,1].set_xlabel('False Positive Rate')
        axes[0,1].set_ylabel('True Positive Rate')
        axes[0,1].set_title('ROC-–∫—Ä–∏–≤—ã–µ', fontweight='bold')
        axes[0,1].legend()
        axes[0,1].grid(True, alpha=0.3)
        
        # 3. –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        if hasattr(self.best_model, 'feature_importances_'):
            feature_importance = pd.DataFrame({
                'feature': self.X.columns,
                'importance': self.best_model.feature_importances_
            }).sort_values('importance', ascending=True).tail(10)
            
            axes[1,0].barh(range(len(feature_importance)), feature_importance['importance'])
            axes[1,0].set_yticks(range(len(feature_importance)))
            axes[1,0].set_yticklabels(feature_importance['feature'])
            axes[1,0].set_title('–¢–æ–ø-10 –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤', fontweight='bold')
            axes[1,0].set_xlabel('–í–∞–∂–Ω–æ—Å—Ç—å')
        
        # 4. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
        model_names = list(self.results.keys())
        accuracies = [self.results[name]['test_accuracy'] for name in model_names]
        
        bars = axes[1,1].bar(model_names, accuracies, color=['skyblue', 'lightgreen', 'gold', 'lightcoral'])
        axes[1,1].set_ylabel('Accuracy')
        axes[1,1].set_title('–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ç–æ—á–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π', fontweight='bold')
        axes[1,1].set_ylim(0, 1)
        
        for bar, acc in zip(bars, accuracies):
            axes[1,1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                        f'{acc:.3f}', ha='center', va='bottom', fontweight='bold')
        
        plt.tight_layout()
        plt.savefig('model_results.png', dpi=300, bbox_inches='tight')
        print("‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ 'model_results.png'")
        plt.show()
    
    def generate_report(self):
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞
        """
        print("\n" + "=" * 80)
        print("üèÜ –§–ò–ù–ê–õ–¨–ù–´–ô –û–¢–ß–ï–¢ –ü–†–û–ï–ö–¢–ê")
        print("=" * 80)
        
        print(f"üìä –î–ê–¢–ê–°–ï–¢: German Credit Data (UCI Machine Learning Repository)")
        print(f"üìà –†–ê–ó–ú–ï–† –î–ê–ù–ù–´–•: {self.df.shape[0]} –∑–∞–ø–∏—Å–µ–π, {self.df.shape[1]} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        print(f"üéØ –ó–ê–î–ê–ß–ê: –ë–∏–Ω–∞—Ä–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∫—Ä–µ–¥–∏—Ç–Ω–æ–≥–æ —Ä–∏—Å–∫–∞")
        print(f"ü§ñ –õ–£–ß–®–ê–Ø –ú–û–î–ï–õ–¨: {self.best_model_name}")
        print(f"üìä –¢–û–ß–ù–û–°–¢–¨: {self.best_accuracy:.3f}")
        print(f"üéØ ROC-AUC: {self.best_auc:.3f}")
        
        if self.best_auc > 0.8:
            quality = "–û–¢–õ–ò–ß–ù–û–ï"
        elif self.best_auc > 0.7:
            quality = "–•–û–†–û–®–ï–ï"
        else:
            quality = "–¢–†–ï–ë–£–ï–¢ –£–õ–£–ß–®–ï–ù–ò–Ø"
        
        print(f"‚úÖ –ö–ê–ß–ï–°–¢–í–û: {quality}")
        
        print(f"\nüíº –ë–ò–ó–ù–ï–°-–¶–ï–ù–ù–û–°–¢–¨:")
        print("‚Ä¢ –ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è –æ—Ü–µ–Ω–∫–∏ –∫—Ä–µ–¥–∏—Ç–Ω—ã—Ö –∑–∞—è–≤–æ–∫")
        print("‚Ä¢ –°–Ω–∏–∂–µ–Ω–∏–µ —Ä–∏—Å–∫–∞ –¥–µ—Ñ–æ–ª—Ç–æ–≤")
        print("‚Ä¢ –£—Å–∫–æ—Ä–µ–Ω–∏–µ –ø—Ä–æ—Ü–µ—Å—Å–∞ –∫—Ä–µ–¥–∏—Ç–æ–≤–∞–Ω–∏—è")
        
        print(f"\nüöÄ –°–õ–ï–î–£–Æ–©–ò–ï –®–ê–ì–ò:")
        print("1. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–æ—Ä–æ–≥–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø–æ–¥ —Ä–∏—Å–∫-–∞–ø–ø–µ—Ç–∏—Ç")
        print("2. –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –¥—Ä–µ–π—Ñ–∞ –¥–∞–Ω–Ω—ã—Ö")
        print("3. –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å CRM —Å–∏—Å—Ç–µ–º–æ–π")
        
    def create_dashboard(self, port=8050):
        """–°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—à–±–æ—Ä–¥–∞"""
        if not hasattr(self, 'results'):
            print("‚ùå –°–Ω–∞—á–∞–ª–∞ –æ–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª–∏!")
            return
        
        try:
            from dashboard import CreditScoringDashboard
            
            print("\nüéÆ –°–û–ó–î–ê–ù–ò–ï –ü–†–û–§–ï–°–°–ò–û–ù–ê–õ–¨–ù–û–ì–û –î–ê–®–ë–û–†–î–ê...")
            print("üìä –í—Å–µ –≥—Ä–∞—Ñ–∏–∫–∏ –±—É–¥—É—Ç –≤ –æ–¥–Ω–æ–º –≤–µ–±-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏")
            print("üåê –û—Ç–∫—Ä–æ–µ—Ç—Å—è –≤ –æ–¥–Ω–æ–π –≤–∫–ª–∞–¥–∫–µ –±—Ä–∞—É–∑–µ—Ä–∞")
            
            dashboard = CreditScoringDashboard(
                df=self.df,
                results=self.results,
                X_test=self.X_test,
                y_test=self.y_test,
                feature_names=self.X.columns
            )
            
            dashboard.run(port=port)
            
        except ImportError as e:
            print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –¥–∞—à–±–æ—Ä–¥: {e}")
            print("üí° –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install dash")

def main():
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∑–∞–ø—É—Å–∫–∞ –ø–∞–π–ø–ª–∞–π–Ω–∞
    """
    print("üéØ –ó–ê–ü–£–°–ö –ü–†–û–ï–ö–¢–ê: –£–ú–ù–´–ô –ö–†–ï–î–ò–¢–ù–´–ô –°–ö–û–†–ò–ù–ì")
    print("=" * 80)
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
    credit_model = CreditScoringModel()
    
    # –ü–æ–ª–Ω—ã–π ML –ø–∞–π–ø–ª–∞–π–Ω
    credit_model.load_data(source='online')  # –∏–ª–∏ 'local' –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
    credit_model.explore_data()
    credit_model.preprocess_data()
    credit_model.train_models()
    credit_model.evaluate_models()
    credit_model.generate_report()

if __name__ == "__main__":
    main()